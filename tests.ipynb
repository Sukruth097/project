{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv  \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string=os.getenv(\"CONNECTION_STRING\")\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_client=blob_service_client.get_container_client(\"testindex-chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container exists\n"
     ]
    }
   ],
   "source": [
    "if container_client.exists():\n",
    "    print(\"Container exists\")\n",
    "else:\n",
    "    print(\"Container does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cracked-output', 'test'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs = container_client.list_blobs()\n",
    "blob_names = set([blob.name.split('/')[0] for blob in blobs])\n",
    "blob_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cracked-output/aHR0cHM6Ly9sbG04NjA5Njc5MDU0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9maWxldXBsb2FkLXRlc3RpbmRleC9sZWJvMTExLnBkZg2.txt',\n",
       " 'test/jeff101.pdf',\n",
       " 'test/jeff102.pdf',\n",
       " 'test/jeff103.pdf',\n",
       " 'test/jeff104.pdf',\n",
       " 'test/jeff105.pdf',\n",
       " 'test/jeff106.pdf',\n",
       " 'test/jeff107.pdf',\n",
       " 'test/jeff108.pdf',\n",
       " 'test/jeff109.pdf',\n",
       " 'test/jeff1ps.pdf',\n",
       " 'test/jesc101.pdf',\n",
       " 'test/jesc102.pdf',\n",
       " 'test/jesc103.pdf',\n",
       " 'test/jesc104.pdf',\n",
       " 'test/jesc105.pdf',\n",
       " 'test/jesc106.pdf',\n",
       " 'test/jesc107.pdf',\n",
       " 'test/jesc108.pdf',\n",
       " 'test/jesc109.pdf',\n",
       " 'test/jesc110.pdf',\n",
       " 'test/jesc111.pdf',\n",
       " 'test/jesc112.pdf',\n",
       " 'test/jesc113.pdf',\n",
       " 'test/jesc1an.pdf',\n",
       " 'test/jesc1ps.pdf',\n",
       " 'test/jess101.pdf',\n",
       " 'test/jess102.pdf',\n",
       " 'test/jess103.pdf',\n",
       " 'test/jess104.pdf',\n",
       " 'test/jess105.pdf',\n",
       " 'test/jess106.pdf',\n",
       " 'test/jess107.pdf',\n",
       " 'test/jess1a1.pdf',\n",
       " 'test/jess1ps.pdf',\n",
       " 'test/rcd.pdf',\n",
       " 'test/researchpaper1.pdf'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs = container_client.list_blobs()\n",
    "blob_names = set([blob.name for blob in blobs])\n",
    "blob_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'cracked-output/aHR0cHM6Ly9sbG04NjA5Njc5MDU0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9maWxldXBsb2FkLXRlc3RpbmRleC9sZWJvMTExLnBkZg2.txt', 'container': 'testindex-chunks', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2024, 8, 22, 15, 48, 11, tzinfo=datetime.timezone.utc), 'etag': '0x8DCC2C1D3ED4DA1', 'size': 37497, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/octet-stream', 'content_encoding': None, 'content_language': None, 'content_md5': bytearray(b'\\xdc\\xf3\\x89\\xd7\\xd6\\x9a\\x8d\\x8b%t!K2+\\xcc#'), 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2024, 8, 22, 15, 48, 11, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': 2, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None}\n"
     ]
    }
   ],
   "source": [
    "blobs = container_client.list_blobs(name_starts_with=\"cracked\")\n",
    "for blob in blobs:\n",
    "    print(blob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"artifact\",exist_ok=True)\n",
    "download_path= \"artifact\"\n",
    "blobs = container_client.list_blobs(name_starts_with=\"cracked-output\")\n",
    "for blob in blobs:\n",
    "    blob_client = container_client.get_blob_client(blob.name)\n",
    "    blob_download_path = os.path.join(download_path, blob.name)\n",
    "    os.makedirs(os.path.dirname(blob_download_path), exist_ok=True)\n",
    "    with open(blob_download_path, \"wb\") as download_file:\n",
    "        download_file.write(blob_client.download_blob().readall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\v-sukruthav\\\\Downloads\\\\project\\\\src'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(r\"C:\\Users\\v-sukruthav\\Downloads\\project\\src\\cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.logger import logger\n",
    "container_client = blob_service_client.get_container_client(\"testindex-chunks\")\n",
    "uploaded_count = 0  \n",
    "folder_path = r\"C:\\Users\\v-sukruthav\\Downloads\\All_textbooks\\jesc1dd\"\n",
    "blob_name=\"test\"\n",
    "logger.info(f\"Starting to upload all the files present in {folder_path}\")\n",
    "logger.info(f\"Total no of files present in folder:{folder_path} are {len(os.listdir(folder_path))}\")\n",
    "for root, _, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        blob_path = os.path.join(blob_name, os.path.relpath(file_path, folder_path))\n",
    "        logger.info(f\"Uploading {file_path} to {blob_path}\")\n",
    "        blob_client = container_client.get_blob_client(blob_path)\n",
    "        with open(file_path, \"rb\") as data:\n",
    "            blob_client.upload_blob(data)\n",
    "        logger.info(f\"Uploaded {file_path} to {blob_path}\")\n",
    "        uploaded_count += 1  # Increment counter\n",
    "logger.info(f\"Total number of files uploaded: {uploaded_count}\")  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.entity.config_entity import DataIngestionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = DataIngestionConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_ingestion_dir': 'artifacts\\\\09_12_2024_15_17_01\\\\DataIngestion',\n",
       " 'raw_data_dir': 'artifacts\\\\09_12_2024_15_17_01\\\\DataIngestion\\\\rawdata',\n",
       " 'processed_data_dir': 'artifacts\\\\09_12_2024_15_17_01\\\\DataIngestion\\\\processed_data',\n",
       " 'metadata_dir': 'artifacts\\\\09_12_2024_15_17_01\\\\DataIngestion\\\\metadata',\n",
       " 'metadata_filename': 'src\\\\metadata\\\\di_metadata.json',\n",
       " 'processed_data_filename': 'processed_data.pdf',\n",
       " 'azure_container_name': 'testindex-chunks',\n",
       " 'azure_blob_name': 'cracked-output'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'src\\\\metadata'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.dirname(dic.metadata_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aHR0cHM6Ly9sbG04NjA5Njc5MDU0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9maWxldXBsb2FkLXRlc3RpbmRleC9sZWJvMTExLnBkZg2.txt',\n",
       " 'jemh1a1.pdf',\n",
       " 'jemh1a2.pdf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(r\"artifacts\\09_11_2024_23_03_42\\DataIngestion\\rawdata\\cracked-output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Case No\n",
      "SAP\n",
      "Issue\n",
      "Resolution\n",
      "Summary\n",
      "Reference Links helped for Resolution\n",
      "\n",
      "\n",
      "2408070030002990\n",
      "Azure/OpenAI/Availability and Service Quality/Poor performance\n",
      "GPT-4o Mini Latency High - 30.95 ms\n",
      "Upon reviewing backend logs, we confirmed latency issues occurred, likely due to increased load on the service. This is a common factor, especially with new models. As of now, latency has returned to normal levels.\n",
      "The customer is facing high latency with Azure OpenAI's GPT-4o Mini, where the latency has increased to 30.95 seconds from the usual average of 181.67 milliseconds. They provided details about the API request parameters and model being used. The issue started on August 6, 2024, and is impacting their services significantly. The last activity on the case involved the assignment of the case to engineers for further investigation.\n",
      "Azure OpenAI Service performance & latency - Azure OpenAI | Microsoft Learn\n",
      "\n",
      "\n",
      "2407300030006340\n",
      "Azure/OpenAI/API Errors and Exceptions/HTTP 400 Invalid Request\n",
      "400 error on open ai azure astound\n",
      "- The Product Team confirmed the duration for the ingestion process is 48 hours.\n",
      "The customer reported a 400 error on OpenAI Azure Astound. They mentioned using the GPT model and provided details of the API request that resulted in a \"Bad Request\" response with status 400. The issue began on July 30, 2024, at 08:56:00.105 UTC. The request configuration and response headers were also shared. The troubleshooting steps included examining the API request and response details. The final solution or resolution to the issue was not provided in the support ticket details.\n",
      "Quickstart - Get started using GPT-35-Turbo and GPT-4 with Azure OpenAI Service - Azure OpenAI Service | Microsoft Learn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Analysis shows successful GET operations for ingestion every 24 hours with a header count of 20, with no issues in the past 60 days.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- An anomaly occurred on August 2nd, where a 400 error was returned within 3 hours after a successful ingestion creation. This was linked to the header count being 22 instead of 20 and the 48-hour duration.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Submitting the ingestion job daily with the same job ID deletes the index and recreates it, leading to downtime.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- You are encountering a 400 error on OpenAI Azure Astound when passing the API key using a Lambda function, resulting in a 'Bad Request' issue. Additionally, they are submitting the ingestion job every day using the same job ID, which causes downtime for inference.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Implement the GET operation within 24 hours after creating the ingestion request to avoid 400 errors.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2408090030003490\n",
      "Azure/OpenAI/Requesting Access to OpenAI\n",
      "Requirements for enterprise agreement for Azure Open AI service\n",
      "Upon investigating the issue, we have determined that the problem you are encountering is related to the requirements for an enterprise agreement for the Azure Open AI service. This matter does not directly involve any technical issues within the scope of the Azure Cognitive Service technical team. As the issue pertains to the requirements of the enterprise agreement, which is outside our technical scope, it is not something that we can address directly. We recommend that you consult with your Sales team, as they will be better positioned to assist with this matter.\n",
      "The customer is inquiring about the requirements for an enterprise agreement for Azure Open AI service. They provided details such as the problem start date, subscription ID, request type, and offer type. The case was transferred to the concern team for clarification as it was out of scope for the current team. The next action required is for the customer to connect with the sales team. The case activities show that the issue is related to Azure open AI services and the customer needs details about them.' metadata={'source': 'data\\\\Book1.xlsx'}\n",
      "page_content='2408190030004790\n",
      "Azure/OpenAI\n",
      "The Retriever retrieves same chunk id for the different chunks using query_type = 'vector'\n",
      "Reproduced the issue from our end and observed the same result upon that we have reached out to product team they have replied that the chunk_id is expected to be 0 for vector search scenarios. So they recommended using another method to differentiate between chunks in their UI as below:\n",
      "When we use query_type = 'vector', the api returns the chunk id 0 for all the chunks.\n",
      "https://learn.microsoft.com/en-us/azure/ai-services/openai/references/azure-search?tabs=python#fields-mapping-options\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use the order of the chunk in the citation list to assign a \"Part 1\" label. For example, if they have two citations from \"hello.txt\", label the first one \"hello.txt - Part 1\" and the second \"hello.txt - Part 2\". For example, we do this in our web app codehttps://github.com/microsoft/sample-app-aoai-chatGPT/blob/7dae506581433ddc6c08a48fd36333e17b253e76/frontend/src/components/Answer/AnswerParser.tsx#L11C1-L23C2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2408160030002510\n",
      "Azure/Cognitive Services/Quota or usage validation\n",
      "Quota Request\n",
      "Not yet resolved\n",
      "The customer requested a quota increase for Azure Document AI-10M tier and specified requirements for gpt 3.5 and gpt 4o. They needed at least 900 TPM for both services in the East US location. The support engineer clarified that they do not handle quota approval processes and advised contacting csgate@microsoft.com for updates. The customer also inquired about raising the quota request effectively to achieve 12 million TPM and asked various questions regarding regional and global quota allocation, pricing, and endpoint creation. The support engineer recommended creating a new support request for detailed statistics and capacity data and provided information on pricing tiers and resource limitations.\n",
      "Azure OpenAI Service - Pricing | Microsoft Azurehttps://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR4xPXO648sJKt4GoXAed-0pUMFE1Rk9CU084RjA0TUlVSUlMWEQzVkJDNCQlQCN0PWcuhttps://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits\n",
      "\n",
      "\n",
      "2408200030003880\n",
      "Azure/OpenAI\n",
      "AI Search resources created by the chat playground get deleted\n",
      "Not yet resolved\n",
      "The customer reported an issue where AI Search resources created by the chat playground were being automatically deleted, except for the final search index, after the ingestion process was completed. This caused a disruption in programmatically running indexers to keep the search index updated. The support team is investigating the unexpected deletions and working with the AI Search Team to determine the cause and find a solution. The latest activity involves the support engineer requesting additional details from the customer to further investigate the problem.\n",
      "Using your data with Azure OpenAI Service - Azure OpenAI | Microsoft Learn\n",
      "\n",
      "\n",
      "2409050030007160\n",
      "Azure/OpenAI/Accuracy or Quality of response\n",
      "Queries regarding openai.ChatCompletion api\n",
      "- When you pass a prompt, the model returns a response as expected.\n",
      "The customer is facing issues with the openai.ChatCompletion API, specifically with the logprobs parameter in the gpt-35-turbo model. They are using Azure cloud services and have provided details related to their Azure subscription. The problem started on September 5, 2024, at 09:42:00 UTC. The support ticket has been assigned to an engineer for further investigation and resolution.\n",
      "What's new in Azure OpenAI Service? - Azure AI services | Microsoft Learn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- However, when you include the logprobs parameter, no response is returned.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- This issue is related to the API version being used. The logprobs parameter may not behave as expected with the current version.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- We recommend changing the API version to 2024-06-01 GA, as it should resolve the issue with logprobs.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- You may also notice that logprobs are returned when using the 2023-03-15 preview or 2024-02-01 GA versions, which may not be the expected behavior.' metadata={'source': 'data\\\\Book1.xlsx'}\n",
      "page_content='- You may also notice that logprobs are returned when using the 2023-03-15 preview or 2024-02-01 GA versions, which may not be the expected behavior.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- We have provided guidance on this and included the necessary steps in the documentation link shared.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2409110030003150\n",
      "Azure/OpenAI/Azure OpenAI Studio/Unable to login\n",
      "OpenAI page not able to work and not able to open studio and Azure Open AI tools also\n",
      "Not yet resolved\n",
      "The customer is experiencing issues with accessing the OpenAI page and Studio on portal.azure.com. They are unable to open the OpenAI tool and facing network errors. Despite having owner access and granted subscription, they have not uploaded a network trace. Troubleshooting involved checking network connection, firewall, and browser settings. The support engineer has collected HAR logs and advised the customer to verify these settings with their network team.' metadata={'source': 'data\\\\Book1.xlsx'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader,Docx2txtLoader,UnstructuredExcelLoader\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file using Docx2txtLoader\n",
    "# loader = UnstructuredExcelLoader(file_path=\"data\\Book1.xlsx\")\n",
    "# pages = loader.load_and_split()\n",
    "\n",
    "# Preprocess the data\n",
    "# data = []\n",
    "# for page in pages:\n",
    "#     print(page)\n",
    "    # Assuming each page contains a row of data\n",
    "#     case_no, sap, issue, resolution, summary, referred_links = page.split('\\n')\n",
    "#     combined_text = f\"{case_no} {sap} {issue} {resolution} {summary} {referred_links}\"\n",
    "#     data.append({\n",
    "#         \"case_no\": case_no,\n",
    "#         \"resolution\": resolution,\n",
    "#         \"referred_links\": referred_links,\n",
    "#         \"combined_text\": combined_text\n",
    "#     })\n",
    "\n",
    "# # Convert to DataFrame-like structure\n",
    "# df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 644 entries, 0 to 643\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Case No                                8 non-null      float64\n",
      " 1   SAP                                    8 non-null      object \n",
      " 2   Issue                                  8 non-null      object \n",
      " 3   Resolution                             8 non-null      object \n",
      " 4   Summary                                8 non-null      object \n",
      " 5   Reference Links helped for Resolution  644 non-null    object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 30.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# !pip install xlrd\n",
    "df = pd.read_csv('data\\llm_data_list.csv',converters={'Reference Links helped for Resolution': str})\n",
    "df.head(10)\n",
    "df.info()\n",
    "\n",
    "# Preprocess the data\n",
    "# df['combined_text'] = df[['case_no', 'sap', 'issue', 'resolution', 'summary', 'referred_links']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case No</th>\n",
       "      <th>SAP</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Reference Links helped for Resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.408070e+15</td>\n",
       "      <td>Azure/OpenAI/Availability and Service Quality/...</td>\n",
       "      <td>GPT-4o Mini Latency High - 30.95 ms</td>\n",
       "      <td>Upon reviewing backend logs, we confirmed late...</td>\n",
       "      <td>The customer is facing high latency with Azure...</td>\n",
       "      <td>Azure OpenAI Service performance &amp; latency - A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.407300e+15</td>\n",
       "      <td>Azure/OpenAI/API Errors and Exceptions/HTTP 40...</td>\n",
       "      <td>400 error on open ai azure astound</td>\n",
       "      <td>- The Product Team confirmed the duration for ...</td>\n",
       "      <td>The customer reported a 400 error on OpenAI Az...</td>\n",
       "      <td>Quickstart - Get started using GPT-35-Turbo an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.408090e+15</td>\n",
       "      <td>Azure/OpenAI/Requesting Access to OpenAI</td>\n",
       "      <td>Requirements for enterprise agreement for Azur...</td>\n",
       "      <td>Upon investigating the issue, we have determin...</td>\n",
       "      <td>The customer is inquiring about the requiremen...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.408190e+15</td>\n",
       "      <td>Azure/OpenAI</td>\n",
       "      <td>The Retriever retrieves same chunk id for the ...</td>\n",
       "      <td>Reproduced the issue from our end and observed...</td>\n",
       "      <td>When we use query_type = 'vector', the api ret...</td>\n",
       "      <td>https://learn.microsoft.com/en-us/azure/ai-ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.408160e+15</td>\n",
       "      <td>Azure/Cognitive Services/Quota or usage valida...</td>\n",
       "      <td>Quota Request</td>\n",
       "      <td>Not yet resolved</td>\n",
       "      <td>The customer requested a quota increase for Az...</td>\n",
       "      <td>Azure OpenAI Service - Pricing | Microsoft Azu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.408200e+15</td>\n",
       "      <td>Azure/OpenAI</td>\n",
       "      <td>AI Search resources created by the chat playgr...</td>\n",
       "      <td>Not yet resolved</td>\n",
       "      <td>The customer reported an issue where AI Search...</td>\n",
       "      <td>Using your data with Azure OpenAI Service - Az...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.409050e+15</td>\n",
       "      <td>Azure/OpenAI/Accuracy or Quality of response</td>\n",
       "      <td>Queries regarding openai.ChatCompletion api</td>\n",
       "      <td>- When you pass a prompt, the model returns a ...</td>\n",
       "      <td>The customer is facing issues with the openai....</td>\n",
       "      <td>What's new in Azure OpenAI Service? - Azure AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.409110e+15</td>\n",
       "      <td>Azure/OpenAI/Azure OpenAI Studio/Unable to login</td>\n",
       "      <td>OpenAI page not able to work and not able to o...</td>\n",
       "      <td>Not yet resolved</td>\n",
       "      <td>The customer is experiencing issues with acces...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Case No                                                SAP  \\\n",
       "0  2.408070e+15  Azure/OpenAI/Availability and Service Quality/...   \n",
       "1  2.407300e+15  Azure/OpenAI/API Errors and Exceptions/HTTP 40...   \n",
       "2  2.408090e+15           Azure/OpenAI/Requesting Access to OpenAI   \n",
       "3  2.408190e+15                                       Azure/OpenAI   \n",
       "4  2.408160e+15  Azure/Cognitive Services/Quota or usage valida...   \n",
       "5  2.408200e+15                                       Azure/OpenAI   \n",
       "6  2.409050e+15       Azure/OpenAI/Accuracy or Quality of response   \n",
       "7  2.409110e+15   Azure/OpenAI/Azure OpenAI Studio/Unable to login   \n",
       "8           NaN                                                NaN   \n",
       "9           NaN                                                NaN   \n",
       "\n",
       "                                               Issue  \\\n",
       "0                GPT-4o Mini Latency High - 30.95 ms   \n",
       "1                 400 error on open ai azure astound   \n",
       "2  Requirements for enterprise agreement for Azur...   \n",
       "3  The Retriever retrieves same chunk id for the ...   \n",
       "4                                      Quota Request   \n",
       "5  AI Search resources created by the chat playgr...   \n",
       "6        Queries regarding openai.ChatCompletion api   \n",
       "7  OpenAI page not able to work and not able to o...   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "                                          Resolution  \\\n",
       "0  Upon reviewing backend logs, we confirmed late...   \n",
       "1  - The Product Team confirmed the duration for ...   \n",
       "2  Upon investigating the issue, we have determin...   \n",
       "3  Reproduced the issue from our end and observed...   \n",
       "4                                   Not yet resolved   \n",
       "5                                   Not yet resolved   \n",
       "6  - When you pass a prompt, the model returns a ...   \n",
       "7                                   Not yet resolved   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  The customer is facing high latency with Azure...   \n",
       "1  The customer reported a 400 error on OpenAI Az...   \n",
       "2  The customer is inquiring about the requiremen...   \n",
       "3  When we use query_type = 'vector', the api ret...   \n",
       "4  The customer requested a quota increase for Az...   \n",
       "5  The customer reported an issue where AI Search...   \n",
       "6  The customer is facing issues with the openai....   \n",
       "7  The customer is experiencing issues with acces...   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "               Reference Links helped for Resolution  \n",
       "0  Azure OpenAI Service performance & latency - A...  \n",
       "1  Quickstart - Get started using GPT-35-Turbo an...  \n",
       "2                                                     \n",
       "3  https://learn.microsoft.com/en-us/azure/ai-ser...  \n",
       "4  Azure OpenAI Service - Pricing | Microsoft Azu...  \n",
       "5  Using your data with Azure OpenAI Service - Az...  \n",
       "6  What's new in Azure OpenAI Service? - Azure AI...  \n",
       "7                                                     \n",
       "8                                                     \n",
       "9                                                     "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Azure OpenAI Service performance & latency - Azure OpenAI | Microsoft Learn'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Reference Links helped for Resolution\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv('data\\llm_data_list.csv')\n",
    "df.head(8)\n",
    "\n",
    "# Format 'Reference Links' column as clickable URLs\n",
    "# df['Reference Links helped for Resolution'] = df['Reference Links helped for Resolution'].apply(lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>')\n",
    "\n",
    "# Export DataFrame to HTML with clickable links\n",
    "# df.to_json('data.json',indent=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case No', 'SAP', 'Issue', 'Resolution', 'Summary',\n",
       "       'Reference Links helped for Resolution'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined_text'] = df[['Case No', 'SAP', 'Issue', 'Resolution', 'Summary']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"2408070030002990.0 Azure/OpenAI/Availability and Service Quality/Poor performance GPT-4o Mini Latency High - 30.95 ms Upon reviewing backend logs, we confirmed latency issues occurred, likely due to increased load on the service. This is a common factor, especially with new models. As of now, latency has returned to normal levels. The customer is facing high latency with Azure OpenAI's GPT-4o Mini, where the latency has increased to 30.95 seconds from the usual average of 181.67 milliseconds. They provided details about the API request parameters and model being used. The issue started on August 6, 2024, and is impacting their services significantly. The last activity on the case involved the assignment of the case to engineers for further investigation.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['combined_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined_text1'] = df.apply(lambda row: f\"For this Case No: {row['Case No']} consisting of SAP: {row['SAP']} while the Issue is: {row['Issue']} and the Resolution is: {row['Resolution']} also the Summary for this case is: {row['Summary']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For this Case No: 2408070030002990.0 consisting of SAP: Azure/OpenAI/Availability and Service Quality/Poor performance while the Issue is: GPT-4o Mini Latency High - 30.95 ms and the Resolution is: Upon reviewing backend logs, we confirmed latency issues occurred, likely due to increased load on the service. This is a common factor, especially with new models. As of now, latency has returned to normal levels. also the Summary for this case is: The customer is facing high latency with Azure OpenAI's GPT-4o Mini, where the latency has increased to 30.95 seconds from the usual average of 181.67 milliseconds. They provided details about the API request parameters and model being used. The issue started on August 6, 2024, and is impacting their services significantly. The last activity on the case involved the assignment of the case to engineers for further investigation.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['combined_text1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_ingestion_dir': 'artifacts\\\\12_12_2024_14_50_02\\\\DataIngestion',\n",
       " 'raw_data_dir': 'artifacts\\\\12_12_2024_14_50_02\\\\DataIngestion\\\\rawdata',\n",
       " 'processed_data_dir': 'artifacts\\\\12_12_2024_14_50_02\\\\DataIngestion\\\\processed_data',\n",
       " 'metadata_dir': 'artifacts\\\\12_12_2024_14_50_02\\\\DataIngestion\\\\metadata',\n",
       " 'metadata_filename': 'src\\\\metadata\\\\di_metadata.json',\n",
       " 'processed_data_filename': 'processed_data.pdf',\n",
       " 'azure_container_name': 'testindex-chunks',\n",
       " 'azure_blob_name': 'cracked-output'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.entity.config_entity import DataIngestionConfig\n",
    "dai = DataIngestionConfig()\n",
    "dai.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
